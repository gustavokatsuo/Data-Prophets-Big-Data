# Pipeline principal - orquestra todo o workflow
import os
import sys
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Imports dos mÃ³dulos criados
from scripts.config import *
from scripts.data_processing import process_data
from scripts.visualization import create_visualizations
from scripts.model import train_model, generate_predictions

def main():
    """Pipeline principal do projeto"""
    print("ðŸš€ INICIANDO PIPELINE DE PREDIÃ‡ÃƒO DE VENDAS")
    print("=" * 60)
    print(f"â±ï¸  Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ðŸ’» Usando {cpu_count()} cores para processamento paralelo")
    print()
    
    # ===== ETAPA 1: PROCESSAMENTO DE DADOS =====
    print("ðŸ“Š ETAPA 1: PROCESSAMENTO DE DADOS")
    print("-" * 40)
    
    try:
        data_dict = process_data(DATA_PATH)
        print("âœ… Dados processados com sucesso!")
    except Exception as e:
        print(f"âŒ Erro no processamento de dados: {e}")
        return None
    
    print()
    
    # ===== ETAPA 2: ANÃLISE VISUAL E INSIGHTS =====
    print("ðŸ“ˆ ETAPA 2: ANÃLISE VISUAL E INSIGHTS")
    print("-" * 40)
    
    try:
        viz_results = create_visualizations(data_dict, output_dir=OUTPUT_DIR)
        print("âœ… AnÃ¡lises visuais geradas com sucesso!")
    except Exception as e:
        print(f"âŒ Erro na geraÃ§Ã£o de visualizaÃ§Ãµes: {e}")
        viz_results = {}
    
    print()
    
    # ===== ETAPA 3: TREINAMENTO DO MODELO =====
    print("ðŸ¤– ETAPA 3: TREINAMENTO DO MODELO")
    print("-" * 40)
    
    try:
        model_path = os.path.join(MODELS_DIR, f'lightgbm_model_{datetime.now().strftime("%Y%m%d_%H%M%S")}.pkl')
        model, wmape = train_model(data_dict, save_model_path=model_path)
        print("âœ… Modelo treinado com sucesso!")
        print(f"ðŸ“Š WMAPE de validaÃ§Ã£o: {wmape:.4f}")
    except Exception as e:
        print(f"âŒ Erro no treinamento do modelo: {e}")
        return None
    
    print()
    
    # ===== ETAPA 4: ANÃLISE DO MODELO =====
    print("ðŸŽ¯ ETAPA 4: ANÃLISE DO MODELO")
    print("-" * 40)
    
    try:
        model_viz_results = create_visualizations(
            data_dict, 
            model=model, 
            output_dir=OUTPUT_DIR
        )
        
        # Salvar feature importance
        if 'feature_importance' in model_viz_results:
            importance_path = os.path.join(OUTPUT_DIR, 'feature_importance.csv')
            model_viz_results['feature_importance'].to_csv(importance_path, index=False)
            print(f"ðŸ’¾ Feature importance salva em: {importance_path}")
        
        print("âœ… AnÃ¡lise do modelo concluÃ­da!")
    except Exception as e:
        print(f"âŒ Erro na anÃ¡lise do modelo: {e}")
    
    print()
    
    # ===== ETAPA 5: GERAÃ‡ÃƒO DE PREDIÃ‡Ã•ES =====
    print("ðŸ”® ETAPA 5: GERAÃ‡ÃƒO DE PREDIÃ‡Ã•ES")
    print("-" * 40)
    
    try:
        predictions_path = os.path.join(OUTPUT_DIR, 'submission_jan2023.csv')
        predictions_df = generate_predictions(
            model, 
            data_dict, 
            weeks=PREDICTION_WEEKS,
            parallel=True,
            save_path=predictions_path
        )
        print("âœ… PrediÃ§Ãµes geradas com sucesso!")
    except Exception as e:
        print(f"âŒ Erro na geraÃ§Ã£o de prediÃ§Ãµes: {e}")
        return None
    
    print()
    
    # ===== ETAPA 6: ANÃLISE DAS PREDIÃ‡Ã•ES =====
    print("ðŸ“Š ETAPA 6: ANÃLISE DAS PREDIÃ‡Ã•ES")
    print("-" * 40)
    
    try:
        pred_viz_results = create_visualizations(
            data_dict,
            predictions_df=predictions_df,
            output_dir=OUTPUT_DIR
        )
        print("âœ… AnÃ¡lise das prediÃ§Ãµes concluÃ­da!")
    except Exception as e:
        print(f"âŒ Erro na anÃ¡lise das prediÃ§Ãµes: {e}")
    
    print()
    
    # ===== RELATÃ“RIO FINAL =====
    print("âœ… PIPELINE CONCLUÃDO COM SUCESSO!")
    print("=" * 60)
    print(f"â±ï¸  Finalizado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ðŸ“ Resultados salvos em: {OUTPUT_DIR}/")
    print(f"ðŸ¤– Modelo salvo em: {MODELS_DIR}/")
    print()
    
    # EstatÃ­sticas finais
    print("ðŸ“ˆ RESUMO DOS RESULTADOS:")
    print(f"â€¢ Total de prediÃ§Ãµes: {len(predictions_df):,}")
    print(f"â€¢ PDVs Ãºnicos: {predictions_df['pdv'].nunique():,}")
    print(f"â€¢ Produtos Ãºnicos: {predictions_df['internal_product_id'].nunique():,}")
    print(f"â€¢ WMAPE do modelo: {wmape:.4f}")
    
    # EstatÃ­sticas por semana
    pred_stats = predictions_df.groupby('week')['predicted_qty'].sum()
    print("\nðŸ”® PREDIÃ‡Ã•ES POR SEMANA:")
    for week in PREDICTION_WEEKS:
        if week in pred_stats.index:
            print(f"  Semana {week}: {pred_stats[week]:>10,} unidades")
    
    print()
    print("ðŸŽ‰ Processo finalizado! Verifique os arquivos de output para mais detalhes.")
    
    return {
        'data': data_dict,
        'model': model,
        'predictions': predictions_df,
        'wmape': wmape
    }

def run_quick_analysis():
    """ExecuÃ§Ã£o rÃ¡pida apenas com anÃ¡lise de dados (sem modelo)"""
    print("ðŸš€ ANÃLISE RÃPIDA DOS DADOS")
    print("=" * 40)
    
    # Processar dados
    data_dict = process_data(DATA_PATH)
    
    # Gerar visualizaÃ§Ãµes
    create_visualizations(data_dict, output_dir=OUTPUT_DIR)
    
    print("âœ… AnÃ¡lise rÃ¡pida concluÃ­da!")
    return data_dict

if __name__ == "__main__":
    # Verificar argumentos da linha de comando
    if len(sys.argv) > 1 and sys.argv[1] == '--quick':
        run_quick_analysis()
    else:
        main()  