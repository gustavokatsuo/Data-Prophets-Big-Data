# Solu√ß√£o para o Hackathon Forecast Big Data
Este reposit√≥rio cont√©m a solu√ß√£o desenvolvida por Gustavo Katsuo (Data Prophets) para o Hackathon Forecast Big Data. O objetivo do desafio √© construir um modelo de Machine Learning para prever a quantidade de vendas semanais por produto (SKU) e por ponto de venda (PDV) para as cinco primeiras semanas de janeiro de 2023, utilizando o hist√≥rico de vendas de 2022 como base.

A m√©trica oficial de avalia√ß√£o √© o WMAPE (Weighted Mean Absolute Percentage Error).

üìà Estrat√©gia e Metodologia
Nossa estrat√©gia foi centrada em um ciclo iterativo de limpeza de dados, engenharia de features robusta e modelagem, com foco constante na otimiza√ß√£o da m√©trica WMAPE.

1. Limpeza e Tratamento de Dados
O primeiro passo foi consolidar e limpar os tr√™s conjuntos de dados fornecidos (transa√ß√µes, produtos e PDVs). As etapas-chave foram:

Integra√ß√£o de Dados: Uni√£o (merge) das tr√™s fontes em um √∫nico DataFrame mestre.

Tratamento de Nulos: Foram identificados e tratados os valores nulos resultantes de inconsist√™ncias no merge (PDVs presentes nas transa√ß√µes mas n√£o no cadastro).

Detec√ß√£o e Remo√ß√£o de Outliers: Atrav√©s da An√°lise Explorat√≥ria de Dados (EDA), foi identificado um pico de vendas massivo e an√¥malo em uma √∫nica semana de setembro de 2022. Este evento foi considerado um outlier e seus dados foram removidos do conjunto de treino para n√£o contaminar o aprendizado do modelo.

2. Engenharia de Features (Feature Engineering)
Esta foi a etapa mais cr√≠tica para a performance do modelo. Foram criadas diversas features para fornecer "pistas" contextuais para o algoritmo:

Features de Tempo: semana_do_ano, dia_da_semana, mes, etc., extra√≠das da data da transa√ß√£o.

Features de Lag: lag_1_semana, lag_2_semanas, etc., para capturar o volume de vendas das semanas imediatamente anteriores.

Features de Janela M√≥vel: media_movel_4_semanas e std_movel_4_semanas para capturar a tend√™ncia recente e a volatilidade das vendas.

Features Categ√≥ricas: Cria√ß√£o de flags bin√°rias para as categorias de produto e PDV mais dominantes (ex. is_package_category), guiado pela an√°lise de Pareto.

Features de Intera√ß√£o: Cria√ß√£o de uma feature poderosa que calcula a m√©dia de vendas de cada marca em cada semana_do_ano, capturando a sazonalidade espec√≠fica da marca.

3. Modelagem
Algoritmo: Foi escolhido o LightGBM (LGBM) Regressor, um modelo de Gradient Boosting conhecido por sua alta velocidade e performance com dados tabulares.

Fun√ß√£o Objetivo: Para alinhar o treinamento diretamente com a m√©trica de avalia√ß√£o (WMAPE), foi utilizado o objetivo objective='regression_l1' (Mean Absolute Error - MAE), que √© um excelente proxy para o WMAPE.

Valida√ß√£o: Foi utilizada uma estrat√©gia de valida√ß√£o temporal, treinando o modelo com os dados at√© a semana 47 de 2022 e validando sua performance nas semanas restantes do ano.

üõ†Ô∏è Stack Tecnol√≥gico
Linguagem: Python 3.11

Bibliotecas Principais: Pandas, NumPy, Scikit-learn, LightGBM, Matplotlib, Seaborn

Ambiente: Jupyter Notebook executado no VS Code com um ambiente virtual (venv).

üöÄ Como Executar o Projeto
Clonar o Reposit√≥rio:

Bash

git clone https://github.com/gustavokatsuo/Data-Prophets-Big-Data.git
cd Data-Prophets-Big-Data
Criar e Ativar o Ambiente Virtual:

Bash

# No Linux/macOS
python3 -m venv venv
source venv/bin/activate

# No Windows
python -m venv venv
.\venv\Scripts\activate
Instalar as Depend√™ncias:

Bash

pip install -r requirements.txt
Adicionar os Dados:

Crie uma pasta chamada data –Ω–∞ raiz do projeto.

Coloque os 3 arquivos .parquet fornecidos pelo hackathon dentro desta pasta. (Nota: os dados n√£o est√£o versionados neste reposit√≥rio por seu tamanho).

Executar o Notebook:

Abra a pasta do projeto no VS Code.

Abra o notebook principal (ex. analise_e_modelo.ipynb).

Selecione o kernel do venv criado.

Execute as c√©lulas em ordem. A √∫ltima c√©lula ir√° gerar o arquivo submissao_final.csv.

üë§ Autor
Gustavo Katsuo