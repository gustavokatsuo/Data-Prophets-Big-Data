# M√≥dulo para an√°lise visual e insights dos dados
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from datetime import datetime
from .config import PLOT_CONFIG
import warnings
warnings.filterwarnings('ignore')

# Configurar estilo dos gr√°ficos
plt.style.use(PLOT_CONFIG['style'])
sns.set_palette(PLOT_CONFIG['palette'])

class DataVisualizer:
    """Classe para an√°lises visuais e insights dos dados"""
    
    def __init__(self, output_dir='output'):
        self.output_dir = output_dir
        
    def plot_data_insights(self, df_raw, df_agg, save_plots=True):
        """Gera insights visuais dos dados"""
        print("üìä Gerando insights visuais dos dados...")
        
        # Criar figura com subplots
        fig, axes = plt.subplots(2, 3, figsize=PLOT_CONFIG['figsize'])
        fig.suptitle('üìä An√°lise Explorat√≥ria dos Dados', fontsize=16, fontweight='bold')
        
        # 1. Distribui√ß√£o de vendas ao longo do ano
        weekly_sales = df_agg.groupby('week_of_year')['qty'].sum()
        axes[0, 0].plot(weekly_sales.index, weekly_sales.values, linewidth=2, color='steelblue')
        axes[0, 0].set_title('üìà Vendas Totais por Semana')
        axes[0, 0].set_xlabel('Semana do Ano')
        axes[0, 0].set_ylabel('Quantidade Vendida')
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. Top 10 PDVs por volume
        top_pdvs = df_agg.groupby('pdv')['qty'].sum().nlargest(10)
        axes[0, 1].barh(range(len(top_pdvs)), top_pdvs.values, color='lightcoral')
        axes[0, 1].set_yticks(range(len(top_pdvs)))
        
        # Tratar PDVs que podem ser strings
        pdv_labels = []
        for x in top_pdvs.index:
            try:
                pdv_labels.append(f'PDV {int(x)}')
            except (ValueError, TypeError):
                pdv_labels.append(f'PDV {str(x)[:8]}')
        axes[0, 1].set_yticklabels(pdv_labels)
        axes[0, 1].set_title('üè™ Top 10 PDVs por Volume')
        axes[0, 1].set_xlabel('Quantidade Vendida')
        
        # 3. Distribui√ß√£o de vendas (log scale)
        non_zero_sales = df_agg[df_agg['qty'] > 0]['qty']
        axes[0, 2].hist(np.log1p(non_zero_sales), bins=50, alpha=0.7, color='mediumseagreen')
        axes[0, 2].set_title('üìä Distribui√ß√£o de Vendas (log+1)')
        axes[0, 2].set_xlabel('log(Quantidade + 1)')
        axes[0, 2].set_ylabel('Frequ√™ncia')
        
        # 4. Correla√ß√£o entre features
        feature_cols = ['qty', 'gross'] + [c for c in df_agg.columns if c.startswith('lag_')][:4]
        corr_matrix = df_agg[feature_cols].corr()
        sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[1, 0])
        axes[1, 0].set_title('üî• Correla√ß√£o entre Features')
        
        # 5. Zero-inflated nature
        zero_pct = (df_agg['qty'] == 0).mean() * 100
        non_zero_pct = 100 - zero_pct
        axes[1, 1].pie([zero_pct, non_zero_pct], labels=['Vendas = 0', 'Vendas > 0'], 
                       autopct='%1.1f%%', colors=['lightgray', 'skyblue'])
        axes[1, 1].set_title(f'üéØ Distribui√ß√£o Zero-Inflated\n({zero_pct:.1f}% zeros)')
        
        # 6. Sazonalidade temporal
        if 'mes' in df_raw.columns:
            monthly_sales = df_raw.groupby('mes')['quantity'].sum()
        else:
            # Fallback: usar trimestres baseados em semanas
            df_agg_temp = df_agg.copy()
            df_agg_temp['trimestre'] = ((df_agg_temp['week_of_year'] - 1) // 13) + 1
            monthly_sales = df_agg_temp.groupby('trimestre')['qty'].sum()
            monthly_sales.index = ['T1', 'T2', 'T3', 'T4']
        
        axes[1, 2].bar(range(len(monthly_sales)), monthly_sales.values, color='plum')
        axes[1, 2].set_title('üìÖ Sazonalidade Temporal')
        axes[1, 2].set_xlabel('Per√≠odo')
        axes[1, 2].set_ylabel('Quantidade Vendida')
        axes[1, 2].set_xticks(range(len(monthly_sales)))
        axes[1, 2].set_xticklabels(monthly_sales.index)
        
        plt.tight_layout()
        
        if save_plots:
            plt.savefig(f'{self.output_dir}/data_insights.png', dpi=PLOT_CONFIG['dpi'], bbox_inches='tight')
        plt.show()
        
        return fig
    
    def plot_training_results(self, model, X_train, y_train, X_val, y_val, features, save_plots=True):
        """Plota resultados do treinamento e feature importance"""
        print("üéØ Analisando resultados do treinamento...")
        
        # Predi√ß√µes usando nossa classe wrapper
        if hasattr(model, 'model'):
            # √â nossa classe LightGBMModel
            train_pred = model.predict(X_train)
            val_pred = model.predict(X_val)
            lgb_model = model.model
            best_iteration = model.best_iteration
        else:
            # √â o modelo do LightGBM diretamente
            try:
                train_pred = model.predict(X_train, num_iteration=model.best_iteration)
                val_pred = model.predict(X_val, num_iteration=model.best_iteration)
            except TypeError:
                train_pred = model.predict(X_train, iteration=model.best_iteration)
                val_pred = model.predict(X_val, iteration=model.best_iteration)
            lgb_model = model
            best_iteration = model.best_iteration
        
        # Criar figura
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle('üéØ An√°lise do Modelo LightGBM', fontsize=16, fontweight='bold')
        
        # 1. Feature Importance
        feature_imp = pd.DataFrame({
            'feature': features,
            'importance': lgb_model.feature_importance(importance_type='gain')
        }).sort_values('importance', ascending=False).head(15)
        
        axes[0, 0].barh(range(len(feature_imp)), feature_imp['importance'], color='steelblue')
        axes[0, 0].set_yticks(range(len(feature_imp)))
        axes[0, 0].set_yticklabels(feature_imp['feature'])
        axes[0, 0].set_title('üî• Top 15 Features mais Importantes')
        axes[0, 0].set_xlabel('Import√¢ncia (Gain)')
        
        # 2. Predi√ß√µes vs Real (Valida√ß√£o)
        sample_size = min(5000, len(val_pred))
        idx = np.random.choice(len(val_pred), sample_size, replace=False)
        axes[0, 1].scatter(y_val.iloc[idx], val_pred[idx], alpha=0.5, color='coral')
        axes[0, 1].plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', linewidth=2)
        axes[0, 1].set_xlabel('Valores Reais')
        axes[0, 1].set_ylabel('Predi√ß√µes')
        axes[0, 1].set_title('üéØ Predi√ß√µes vs Real (Valida√ß√£o)')
        
        # 3. Distribui√ß√£o dos res√≠duos
        residuals = y_val - val_pred
        axes[1, 0].hist(residuals, bins=50, alpha=0.7, color='lightgreen')
        axes[1, 0].set_title('üìä Distribui√ß√£o dos Res√≠duos')
        axes[1, 0].set_xlabel('Res√≠duos')
        axes[1, 0].set_ylabel('Frequ√™ncia')
        axes[1, 0].axvline(0, color='red', linestyle='--', linewidth=2)
        
        # 4. Learning Curve
        if hasattr(model, 'evals_result_'):
            eval_results = model.evals_result_
            train_scores = eval_results['training']['l1']
            val_scores = eval_results['valid_1']['l1']
            
            axes[1, 1].plot(train_scores, label='Treino', color='blue', linewidth=2)
            axes[1, 1].plot(val_scores, label='Valida√ß√£o', color='orange', linewidth=2)
            axes[1, 1].set_title('üìà Curva de Aprendizado')
            axes[1, 1].set_xlabel('Itera√ß√µes')
            axes[1, 1].set_ylabel('MAE')
            axes[1, 1].legend()
            axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_plots:
            plt.savefig(f'{self.output_dir}/training_results.png', dpi=PLOT_CONFIG['dpi'], bbox_inches='tight')
        plt.show()
        
        return feature_imp, fig
    
    def plot_predictions_summary(self, predictions_df, save_plots=True):
        """Gera gr√°fico resumo das predi√ß√µes"""
        print("üìä Gerando resumo visual das predi√ß√µes...")
        
        plt.figure(figsize=(12, 6))
        week_totals = predictions_df.groupby('semana')['quantidade'].sum()
        plt.bar(week_totals.index, week_totals.values, color='steelblue', alpha=0.8)
        plt.title('üîÆ Predi√ß√µes Totais por Semana - Janeiro 2023', fontsize=14, fontweight='bold')
        plt.xlabel('Semana')
        plt.ylabel('Quantidade Predita')
        plt.grid(True, alpha=0.3)
        
        # Adicionar valores nas barras
        for i, v in enumerate(week_totals.values):
            plt.text(i+1, v + v*0.01, f'{v:,.0f}', ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        
        if save_plots:
            plt.savefig(f'{self.output_dir}/predictions_summary.png', dpi=PLOT_CONFIG['dpi'], bbox_inches='tight')
        plt.show()
        
        return plt.gcf()
    
    def print_data_stats(self, stats):
        """Imprime estat√≠sticas descritivas dos dados"""
        print("\nüìà ESTAT√çSTICAS DESCRITIVAS:")
        print(f"‚Ä¢ Total de registros: {stats['total_records']:,}")
        print(f"‚Ä¢ PDVs √∫nicos: {stats['unique_pdvs']:,}")
        print(f"‚Ä¢ Produtos √∫nicos: {stats['unique_products']:,}")
        print(f"‚Ä¢ Vendas m√©dias por semana: {stats['mean_sales']:.2f}")
        print(f"‚Ä¢ Vendas mediana: {stats['median_sales']:.2f}")
        print(f"‚Ä¢ Percentual de zeros: {stats['zero_percentage']:.1f}%")
        print(f"‚Ä¢ Valor bruto m√©dio: R$ {stats['mean_gross_value']:.2f}")
        print(f"‚Ä¢ Range de semanas: {stats['weeks_range'][0]} - {stats['weeks_range'][1]}")
    
    def print_model_metrics(self, train_pred, val_pred, y_train, y_val):
        """Imprime m√©tricas detalhadas do modelo"""
        from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
        
        train_mae = mean_absolute_error(y_train, train_pred)
        val_mae = mean_absolute_error(y_val, val_pred)
        train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))
        val_rmse = np.sqrt(mean_squared_error(y_val, val_pred))
        train_r2 = r2_score(y_train, train_pred)
        val_r2 = r2_score(y_val, val_pred)
        
        print(f"\nüéØ M√âTRICAS DETALHADAS:")
        print(f"‚Ä¢ MAE Treino: {train_mae:.4f} | Valida√ß√£o: {val_mae:.4f}")
        print(f"‚Ä¢ RMSE Treino: {train_rmse:.4f} | Valida√ß√£o: {val_rmse:.4f}")
        print(f"‚Ä¢ R¬≤ Treino: {train_r2:.4f} | Valida√ß√£o: {val_r2:.4f}")
        print(f"‚Ä¢ WMAPE Treino: {np.sum(np.abs(train_pred - y_train)) / np.sum(y_train):.4f}")
        print(f"‚Ä¢ WMAPE Valida√ß√£o: {np.sum(np.abs(val_pred - y_val)) / np.sum(y_val):.4f}")
    
    def print_feature_importance(self, feature_importance):
        """Imprime top features mais importantes"""
        print(f"\nüî• TOP 10 FEATURES MAIS IMPORTANTES:")
        for i, (feat, imp) in enumerate(feature_importance.head(10).values):
            print(f"{i+1:2d}. {feat:<15} ‚Üí {imp:>8.0f}")
    
    def print_predictions_stats(self, predictions_df):
        """Imprime estat√≠sticas das predi√ß√µes"""
        pred_stats = predictions_df.groupby('semana')['quantidade'].agg(['sum', 'mean', 'std'])
        print(f"\nüìä ESTAT√çSTICAS DAS PREDI√á√ïES POR SEMANA:")
        for week in [1, 2, 3, 4, 5]:
            if week in pred_stats.index:
                stats = pred_stats.loc[week]
                print(f"  Semana {week}: Total={stats['sum']:>8,.0f} | M√©dia={stats['mean']:>6.1f} | Std={stats['std']:>6.1f}")

def create_visualizations(data_dict, model=None, predictions_df=None, output_dir='output'):
    """Fun√ß√£o principal para criar todas as visualiza√ß√µes"""
    visualizer = DataVisualizer(output_dir)
    
    # Insights dos dados
    visualizer.plot_data_insights(data_dict['raw_data'], data_dict['aggregated_data'])
    visualizer.print_data_stats(data_dict['stats'])
    
    results = {}
    
    # An√°lise do modelo se fornecido
    if model is not None:
        X_train, y_train = data_dict['train_data']
        X_val, y_val = data_dict['validation_data']
        
        feature_importance, _ = visualizer.plot_training_results(
            model, X_train, y_train, X_val, y_val, data_dict['feature_columns']
        )
        
        # Predi√ß√µes para m√©tricas
        if hasattr(model, 'model'):
            # √â nossa classe LightGBMModel
            train_pred = model.predict(X_train)
            val_pred = model.predict(X_val)
        else:
            # √â o modelo do LightGBM diretamente
            try:
                train_pred = model.predict(X_train, num_iteration=model.best_iteration)
                val_pred = model.predict(X_val, num_iteration=model.best_iteration)
            except TypeError:
                train_pred = model.predict(X_train, iteration=model.best_iteration)
                val_pred = model.predict(X_val, iteration=model.best_iteration)
        
        visualizer.print_model_metrics(train_pred, val_pred, y_train, y_val)
        visualizer.print_feature_importance(feature_importance)
        
        results['feature_importance'] = feature_importance
    
    # An√°lise das predi√ß√µes se fornecidas
    if predictions_df is not None:
        visualizer.plot_predictions_summary(predictions_df)
        visualizer.print_predictions_stats(predictions_df)
        results['predictions_plot'] = True
    
    return results